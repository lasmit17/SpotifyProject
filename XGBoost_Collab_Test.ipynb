{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lasmit17/SpotifyProject/blob/master/XGBoost_Collab_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Packages, Libraries, Models...\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import xgboost as xgb \n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, precision_recall_curve, auc, average_precision_score\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "FUrWrHowJVzC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reading CSVs\n",
        "luke_df_2016 = pd.read_csv(f'Luke_2016_Top_Songs.csv')\n",
        "luke_df_2017 = pd.read_csv(f'Luke_2017_Top_Songs.csv')\n",
        "luke_df_2018 = pd.read_csv(f'Luke_2018_Top_Songs.csv')\n",
        "luke_df_2019 = pd.read_csv(f'Luke_2019_Top_Songs.csv')\n",
        "luke_df_2020 = pd.read_csv(f'Luke_2020_Top_Songs.csv')\n",
        "\n",
        "jp_df_2017 = pd.read_csv(f'jp_2017_Top_Songs.csv')\n",
        "jp_df_2018 = pd.read_csv(f\"jp_2018_Top_Songs.csv\")\n",
        "jp_df_2019 = pd.read_csv(f\"jp_2019_Top_Songs.csv\")\n",
        "jp_df_2020 = pd.read_csv(f\"jp_2020_Top_Songs.csv\")\n",
        "\n",
        "fabian_df_2018 = pd.read_csv(f\"FP_2018_Top_Songs.csv\")\n",
        "fabian_df_2019 = pd.read_csv(f\"fp_2019_Top_Songs.csv\")\n",
        "fabian_df_2020 = pd.read_csv(f\"FP_2020_Top_Songs.csv\")\n",
        "fabian_df_2017 = pd.read_csv(f\"FP_2017_Top_Songs.csv\")"
      ],
      "metadata": {
        "id": "nZRvPLZ1Ijdx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Release Year\n",
        "#Creating a function to add a new variable to the dataframes, the song release year\n",
        "def get_years(df):\n",
        "    years = []\n",
        "    for date in df['release_date'].values:\n",
        "        if '-' in date:\n",
        "            years.append(date.split('-')[0])\n",
        "        else:\n",
        "            years.append(date)\n",
        "    df['release_year'] = years\n",
        "    return df\n",
        "\n",
        "\n",
        "#Adding release year to each dataframe for each individual\n",
        "luke_df_2016 = get_years(luke_df_2016)\n",
        "luke_df_2017 = get_years(luke_df_2017)\n",
        "luke_df_2018 = get_years(luke_df_2018)\n",
        "luke_df_2019 = get_years(luke_df_2019)\n",
        "luke_df_2020 = get_years(luke_df_2020)\n",
        "\n",
        "jp_df_2017 = get_years(jp_df_2017)\n",
        "jp_df_2018 = get_years(jp_df_2018)\n",
        "jp_df_2019 = get_years(jp_df_2019)\n",
        "jp_df_2020 = get_years(jp_df_2020)\n",
        "\n",
        "fabian_df_2018 = get_years(fabian_df_2018)\n",
        "fabian_df_2019 = get_years(fabian_df_2019)\n",
        "fabian_df_2020 = get_years(fabian_df_2020)\n",
        "fabian_df_2017 = get_years(fabian_df_2017)"
      ],
      "metadata": {
        "id": "RwqKWmx6ffAo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Joining DataFrames\n",
        "#combining each person's data\n",
        "luke_df_concat = pd.concat([luke_df_2016, luke_df_2017, luke_df_2018, luke_df_2019, luke_df_2020], ignore_index=True, axis=0)\n",
        "luke_df_concat['users_name'] = \"Luke\"\n",
        "\n",
        "jp_df_concat = pd.concat([jp_df_2017, jp_df_2018, jp_df_2019, jp_df_2020], ignore_index=True, axis=0)\n",
        "jp_df_concat['users_name'] = \"JP\"\n",
        "\n",
        "fabian_df_concat = pd.concat([fabian_df_2017, fabian_df_2018, fabian_df_2019, fabian_df_2020], ignore_index=True, axis=0)\n",
        "fabian_df_concat['users_name'] = \"Fabian\"\n",
        "\n",
        "#Combining every data frame together into one\n",
        "all_df = pd.concat([luke_df_concat, jp_df_concat, fabian_df_concat], ignore_index=True, axis=0)\n",
        "\n",
        "all_df[\"release_year\"] = pd.to_numeric(all_df[\"release_year\"])"
      ],
      "metadata": {
        "id": "Y2U4Xn3Hfp2h"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove Repeats\n",
        "# remove repeats on individual playlists\n",
        "def remove_repeats(df):\n",
        "    rows_old = range(len(df['name']))\n",
        "    rows_new = []\n",
        "    skips = []\n",
        "    for i in range(len(df['name'])):\n",
        "        for j in range(i+1, len(df['name'])):\n",
        "            if (df['name'][i] == df['name'][j]) and (df['artist'][i] == df['artist'][j]):\n",
        "                skips.append(j)\n",
        "    for row in rows_old:\n",
        "        if not row in skips:\n",
        "            rows_new.append(row)\n",
        "    df = df.iloc[rows_new,:].reset_index(drop=True)\n",
        "    return df\n",
        "remove_repeats(all_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        },
        "id": "yaFdXkSNfuut",
        "outputId": "fb7721fd-ab3f-4d65-bcd3-327563d870fe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           name                                album  \\\n",
              "0                    In the Bag                             GO:OD AM   \n",
              "1                      Gasoline                    BADLANDS (Deluxe)   \n",
              "2                        Closer                               Closer   \n",
              "3                       Morocco             Mountains Beaches Cities   \n",
              "4                Temporary Love                       Temporary Love   \n",
              "...                         ...                                  ...   \n",
              "1206                       1975                                 1975   \n",
              "1207                 Whasgood?!                           Whasgood?!   \n",
              "1208     You Can't Hold Me Down  An Ordinary Day In An Unusual Place   \n",
              "1209  Satisfied 'N' Tickled Too             Satisfied 'N Tickled Too   \n",
              "1210     This Land Is Your Land                            Naturally   \n",
              "\n",
              "                            artist release_date  length  popularity  \\\n",
              "0                       Mac Miller   2015-09-18  275506          52   \n",
              "1                           Halsey   2015-08-28  199593          73   \n",
              "2                 The Chainsmokers   2016-07-29  244960          85   \n",
              "3                        Moon Taxi   2013-09-10  208080           0   \n",
              "4                       The Brinks   2015-12-04  205129          46   \n",
              "...                            ...          ...     ...         ...   \n",
              "1206                         MAJAN   2019-05-10  223795          54   \n",
              "1207                    blackwave.   2018-06-08  221800          33   \n",
              "1208                           Us3   2001-01-01  261466          44   \n",
              "1209                     Taj Mahal   1976-06-25  326826          43   \n",
              "1210  Sharon Jones & The Dap-Kings   2005-01-25  271440          50   \n",
              "\n",
              "      acousticness  danceability  energy  instrumentalness  ...  loudness  \\\n",
              "0           0.3010         0.717   0.634          0.000000  ...    -6.887   \n",
              "1           0.2230         0.731   0.580          0.000000  ...    -7.328   \n",
              "2           0.4140         0.748   0.524          0.000000  ...    -5.599   \n",
              "3           0.0178         0.616   0.894          0.000103  ...    -3.209   \n",
              "4           0.6560         0.714   0.555          0.000289  ...    -7.550   \n",
              "...            ...           ...     ...               ...  ...       ...   \n",
              "1206        0.2340         0.635   0.473          0.000000  ...   -10.137   \n",
              "1207        0.0311         0.851   0.669          0.000086  ...    -4.259   \n",
              "1208        0.0229         0.824   0.723          0.011100  ...    -4.814   \n",
              "1209        0.7470         0.841   0.591          0.037100  ...    -9.081   \n",
              "1210        0.4010         0.612   0.748          0.000002  ...    -3.654   \n",
              "\n",
              "      speechiness    tempo  valence  time_signature  key  mode  \\\n",
              "0          0.4090  143.812    0.564               4    1     1   \n",
              "1          0.0399  119.997    0.319               4   10     0   \n",
              "2          0.0338   95.010    0.661               4    8     1   \n",
              "3          0.0508  115.077    0.542               4    1     0   \n",
              "4          0.0459  102.971    0.329               4    6     0   \n",
              "...           ...      ...      ...             ...  ...   ...   \n",
              "1206       0.0623  140.094    0.191               4    8     1   \n",
              "1207       0.0721  109.974    0.835               4    1     1   \n",
              "1208       0.0305  116.013    0.963               4    1     1   \n",
              "1209       0.0527  134.796    0.817               4    3     1   \n",
              "1210       0.0318   98.077    0.905               4    6     1   \n",
              "\n",
              "                                       uri release_year  users_name  \n",
              "0     spotify:track:7odIekt1GqLVEAAWdnd9mJ         2015        Luke  \n",
              "1     spotify:track:2IO7yf562c1zLzpanal1DT         2015        Luke  \n",
              "2     spotify:track:7BKLCZ1jbUBVqRi2FVlTVw         2016        Luke  \n",
              "3     spotify:track:30lgD1UuHczwlxa7NZFeSQ         2013        Luke  \n",
              "4     spotify:track:2U6hcDLZHYRSd9Up0mMe9W         2015        Luke  \n",
              "...                                    ...          ...         ...  \n",
              "1206  spotify:track:6mf2YhtRwQUdnORRrRQ3hP         2019      Fabian  \n",
              "1207  spotify:track:5vhwne4NXUgFdtbnTMz37m         2018      Fabian  \n",
              "1208  spotify:track:366E1dYGmFM75DxX0yxlSq         2001      Fabian  \n",
              "1209  spotify:track:4v6gpq8gNsvKekCc2rgXb5         1976      Fabian  \n",
              "1210  spotify:track:3JiUvMTBqbturJ5cKhxgWH         2005      Fabian  \n",
              "\n",
              "[1211 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0865c257-f64e-40b7-b12f-7edf59a5aad9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>album</th>\n",
              "      <th>artist</th>\n",
              "      <th>release_date</th>\n",
              "      <th>length</th>\n",
              "      <th>popularity</th>\n",
              "      <th>acousticness</th>\n",
              "      <th>danceability</th>\n",
              "      <th>energy</th>\n",
              "      <th>instrumentalness</th>\n",
              "      <th>...</th>\n",
              "      <th>loudness</th>\n",
              "      <th>speechiness</th>\n",
              "      <th>tempo</th>\n",
              "      <th>valence</th>\n",
              "      <th>time_signature</th>\n",
              "      <th>key</th>\n",
              "      <th>mode</th>\n",
              "      <th>uri</th>\n",
              "      <th>release_year</th>\n",
              "      <th>users_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In the Bag</td>\n",
              "      <td>GO:OD AM</td>\n",
              "      <td>Mac Miller</td>\n",
              "      <td>2015-09-18</td>\n",
              "      <td>275506</td>\n",
              "      <td>52</td>\n",
              "      <td>0.3010</td>\n",
              "      <td>0.717</td>\n",
              "      <td>0.634</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-6.887</td>\n",
              "      <td>0.4090</td>\n",
              "      <td>143.812</td>\n",
              "      <td>0.564</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>spotify:track:7odIekt1GqLVEAAWdnd9mJ</td>\n",
              "      <td>2015</td>\n",
              "      <td>Luke</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Gasoline</td>\n",
              "      <td>BADLANDS (Deluxe)</td>\n",
              "      <td>Halsey</td>\n",
              "      <td>2015-08-28</td>\n",
              "      <td>199593</td>\n",
              "      <td>73</td>\n",
              "      <td>0.2230</td>\n",
              "      <td>0.731</td>\n",
              "      <td>0.580</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-7.328</td>\n",
              "      <td>0.0399</td>\n",
              "      <td>119.997</td>\n",
              "      <td>0.319</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>spotify:track:2IO7yf562c1zLzpanal1DT</td>\n",
              "      <td>2015</td>\n",
              "      <td>Luke</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Closer</td>\n",
              "      <td>Closer</td>\n",
              "      <td>The Chainsmokers</td>\n",
              "      <td>2016-07-29</td>\n",
              "      <td>244960</td>\n",
              "      <td>85</td>\n",
              "      <td>0.4140</td>\n",
              "      <td>0.748</td>\n",
              "      <td>0.524</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-5.599</td>\n",
              "      <td>0.0338</td>\n",
              "      <td>95.010</td>\n",
              "      <td>0.661</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>spotify:track:7BKLCZ1jbUBVqRi2FVlTVw</td>\n",
              "      <td>2016</td>\n",
              "      <td>Luke</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Morocco</td>\n",
              "      <td>Mountains Beaches Cities</td>\n",
              "      <td>Moon Taxi</td>\n",
              "      <td>2013-09-10</td>\n",
              "      <td>208080</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0178</td>\n",
              "      <td>0.616</td>\n",
              "      <td>0.894</td>\n",
              "      <td>0.000103</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.209</td>\n",
              "      <td>0.0508</td>\n",
              "      <td>115.077</td>\n",
              "      <td>0.542</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>spotify:track:30lgD1UuHczwlxa7NZFeSQ</td>\n",
              "      <td>2013</td>\n",
              "      <td>Luke</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Temporary Love</td>\n",
              "      <td>Temporary Love</td>\n",
              "      <td>The Brinks</td>\n",
              "      <td>2015-12-04</td>\n",
              "      <td>205129</td>\n",
              "      <td>46</td>\n",
              "      <td>0.6560</td>\n",
              "      <td>0.714</td>\n",
              "      <td>0.555</td>\n",
              "      <td>0.000289</td>\n",
              "      <td>...</td>\n",
              "      <td>-7.550</td>\n",
              "      <td>0.0459</td>\n",
              "      <td>102.971</td>\n",
              "      <td>0.329</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>spotify:track:2U6hcDLZHYRSd9Up0mMe9W</td>\n",
              "      <td>2015</td>\n",
              "      <td>Luke</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1206</th>\n",
              "      <td>1975</td>\n",
              "      <td>1975</td>\n",
              "      <td>MAJAN</td>\n",
              "      <td>2019-05-10</td>\n",
              "      <td>223795</td>\n",
              "      <td>54</td>\n",
              "      <td>0.2340</td>\n",
              "      <td>0.635</td>\n",
              "      <td>0.473</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-10.137</td>\n",
              "      <td>0.0623</td>\n",
              "      <td>140.094</td>\n",
              "      <td>0.191</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>spotify:track:6mf2YhtRwQUdnORRrRQ3hP</td>\n",
              "      <td>2019</td>\n",
              "      <td>Fabian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1207</th>\n",
              "      <td>Whasgood?!</td>\n",
              "      <td>Whasgood?!</td>\n",
              "      <td>blackwave.</td>\n",
              "      <td>2018-06-08</td>\n",
              "      <td>221800</td>\n",
              "      <td>33</td>\n",
              "      <td>0.0311</td>\n",
              "      <td>0.851</td>\n",
              "      <td>0.669</td>\n",
              "      <td>0.000086</td>\n",
              "      <td>...</td>\n",
              "      <td>-4.259</td>\n",
              "      <td>0.0721</td>\n",
              "      <td>109.974</td>\n",
              "      <td>0.835</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>spotify:track:5vhwne4NXUgFdtbnTMz37m</td>\n",
              "      <td>2018</td>\n",
              "      <td>Fabian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1208</th>\n",
              "      <td>You Can't Hold Me Down</td>\n",
              "      <td>An Ordinary Day In An Unusual Place</td>\n",
              "      <td>Us3</td>\n",
              "      <td>2001-01-01</td>\n",
              "      <td>261466</td>\n",
              "      <td>44</td>\n",
              "      <td>0.0229</td>\n",
              "      <td>0.824</td>\n",
              "      <td>0.723</td>\n",
              "      <td>0.011100</td>\n",
              "      <td>...</td>\n",
              "      <td>-4.814</td>\n",
              "      <td>0.0305</td>\n",
              "      <td>116.013</td>\n",
              "      <td>0.963</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>spotify:track:366E1dYGmFM75DxX0yxlSq</td>\n",
              "      <td>2001</td>\n",
              "      <td>Fabian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1209</th>\n",
              "      <td>Satisfied 'N' Tickled Too</td>\n",
              "      <td>Satisfied 'N Tickled Too</td>\n",
              "      <td>Taj Mahal</td>\n",
              "      <td>1976-06-25</td>\n",
              "      <td>326826</td>\n",
              "      <td>43</td>\n",
              "      <td>0.7470</td>\n",
              "      <td>0.841</td>\n",
              "      <td>0.591</td>\n",
              "      <td>0.037100</td>\n",
              "      <td>...</td>\n",
              "      <td>-9.081</td>\n",
              "      <td>0.0527</td>\n",
              "      <td>134.796</td>\n",
              "      <td>0.817</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>spotify:track:4v6gpq8gNsvKekCc2rgXb5</td>\n",
              "      <td>1976</td>\n",
              "      <td>Fabian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1210</th>\n",
              "      <td>This Land Is Your Land</td>\n",
              "      <td>Naturally</td>\n",
              "      <td>Sharon Jones &amp; The Dap-Kings</td>\n",
              "      <td>2005-01-25</td>\n",
              "      <td>271440</td>\n",
              "      <td>50</td>\n",
              "      <td>0.4010</td>\n",
              "      <td>0.612</td>\n",
              "      <td>0.748</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.654</td>\n",
              "      <td>0.0318</td>\n",
              "      <td>98.077</td>\n",
              "      <td>0.905</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>spotify:track:3JiUvMTBqbturJ5cKhxgWH</td>\n",
              "      <td>2005</td>\n",
              "      <td>Fabian</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1211 rows Ã— 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0865c257-f64e-40b7-b12f-7edf59a5aad9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0865c257-f64e-40b7-b12f-7edf59a5aad9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0865c257-f64e-40b7-b12f-7edf59a5aad9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Scaling Variables 0<var<1\n",
        "# Create function to do linear transformation on variable to change value to [0,1]\n",
        "def convert_scale(df, col):\n",
        "    df[col + '_old'] = df[col]\n",
        "    new_max = 1\n",
        "    new_min = 0\n",
        "    new_range = new_max-new_min\n",
        "    max_val = df[col].max()\n",
        "    min_val=df[col].min()\n",
        "    val_range = max_val - min_val\n",
        "    df[col]=df[col].apply(lambda x: (((x-min_val)*new_range)/val_range)+new_min)\n",
        "    return\n",
        "\n",
        "\n",
        "\n",
        "#Setting the numerical spotify features\n",
        "numeric_spotify_features = ['energy',\n",
        "    'valence',\n",
        "    'danceability',\n",
        "    'liveness',\n",
        "    'speechiness',\n",
        "    'instrumentalness',\n",
        "    'acousticness',\n",
        "    'loudness',\n",
        "    'length',\n",
        "    'popularity',\n",
        "    'tempo',\n",
        "    'release_year']\n",
        "\n",
        "\n",
        "for col in numeric_spotify_features:\n",
        "    convert_scale(all_df, col)"
      ],
      "metadata": {
        "id": "QR-1xwRUf06I"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#HotEncoding Variables\n",
        "#Now we need to address the categorical variables. First, we will utilize One Hot Encoder\n",
        "ohe = OneHotEncoder()\n",
        "ohe_results = ohe.fit_transform(all_df[['time_signature', 'mode', 'key']])\n",
        "onehot_df = pd.DataFrame(ohe_results.toarray(), columns=['time_signature_1', 'time_signature_2',\n",
        "                                                     'time_signature_3', 'time_signature_4',\n",
        "                                                     'mode_1', 'mode_2',\n",
        "                                                     'key_1', 'key_2', 'key_3', 'key_4', 'key_5', 'key_6',\n",
        "                                                     'key_7', 'key_8', 'key_9', 'key_10', 'key_11', 'key_12'])\n",
        "all_df = pd.concat([all_df, onehot_df], axis=1)"
      ],
      "metadata": {
        "id": "JXFqb8Ocf9QA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Combine all Features\n",
        "#Finally, we combine all of our features used for prediction into one list\n",
        "all_spotify_features = ['energy',\n",
        "    'valence',\n",
        "    'danceability',\n",
        "    'liveness',\n",
        "    'speechiness',\n",
        "    'instrumentalness',\n",
        "    'acousticness',\n",
        "    'loudness',\n",
        "    'length',\n",
        "    'popularity',\n",
        "    'tempo',\n",
        "    'release_year',\n",
        "    'time_signature_1',\n",
        "    'time_signature_2',\n",
        "    'time_signature_3',\n",
        "    'time_signature_4',\n",
        "    'mode_1',\n",
        "    'mode_2',\n",
        "    'key_1',\n",
        "    'key_2',\n",
        "    'key_3',\n",
        "    'key_4',\n",
        "    'key_5',\n",
        "    'key_6',\n",
        "    'key_7',\n",
        "    'key_8',\n",
        "    'key_9',\n",
        "    'key_10',\n",
        "    'key_11',\n",
        "    'key_12']\n"
      ],
      "metadata": {
        "id": "UIpW_65VgNHa"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PREP FINISHED\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "MODELS BEGIN"
      ],
      "metadata": {
        "id": "4Y2MEFyGgTsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Set X,Y, Split Train/Test\n",
        "#Now, we can finally set our X and y values. X will be all the Spotify features provided above and y will be each individual's name\n",
        "X = all_df[all_spotify_features]\n",
        "y = all_df['users_name']\n",
        "\n",
        "#Here we split our data up into training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=123)\n",
        "\n"
      ],
      "metadata": {
        "id": "55jwbt91gXG2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOGISTIC REGRESSION"
      ],
      "metadata": {
        "id": "jq0Hh6lsgkOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Pipeline, Fitting, Predicting\n",
        "#Setting up a pipeline that scales and then utilizes multinomial logistic regression\n",
        "pipe = Pipeline([('scaler', StandardScaler()),     # Step 1\n",
        "                 ('model', LogisticRegression(multi_class='multinomial', solver='lbfgs')) # Step 2\n",
        "                 ])\n",
        "#Fitting and predicting with our data\n",
        "pipe.fit(X_train, y_train)\n",
        "pred_logi = pipe.predict(X_test)\n",
        "\n",
        "#print(\"Accuracy:\",metrics.accuracy_score(y_test, pred_logi))"
      ],
      "metadata": {
        "id": "sPViZZ1LgiB-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cross-validation\n",
        "cv = KFold(n_splits=10, random_state=123, shuffle=True)\n",
        "scores = cross_val_score(pipe, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "scores\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vpy8M2vagtTW",
        "outputId": "581c0d5c-3e84-42a0-c67d-46781ca7019c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.67346939, 0.62244898, 0.59183673, 0.67346939, 0.59183673,\n",
              "       0.6185567 , 0.59793814, 0.58762887, 0.58762887, 0.53608247])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBOOST"
      ],
      "metadata": {
        "id": "MUem54zdkJnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#XGBoost\n",
        "\n",
        "#Setting Luke to 2, JP to 1, and Fabian to 0 in order to utilize XGBoost\n",
        "#This is our base model for XGBoost\n",
        "all_df[\"users_name\"] = all_df['users_name'].replace({\"Luke\":2,\"JP\":1,\"Fabian\":0})\n",
        "\n",
        "X = all_df[all_spotify_features]\n",
        "y = all_df['users_name']\n",
        "data_dmatrix = xgb.DMatrix(data=X,label=y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=123)\n",
        "\n",
        "xg_reg = xgb.XGBClassifier(objective ='multi:softmax', colsample_bytree = 0.3, learning_rate = 0.1,\n",
        "                max_depth = 5, alpha = 10, n_estimators = 10, num_classes = 3)\n",
        "xg_reg.fit(X_train,y_train)\n",
        "all_df.users_name\n",
        "pred_xgb = xg_reg.predict(X_test)"
      ],
      "metadata": {
        "id": "ACNky-w8htn7"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#XGBoost parameters\n",
        "mse_xgb = np.sqrt(mean_squared_error(y_test, pred_xgb))\n",
        "print(\"MSE: %f\" % (mse_xgb))\n",
        "\n",
        "xgb_initial_score = cross_val_score(xg_reg, X, y, cv=10)\n",
        "xgb_initial_score\n",
        "\n",
        "xgb_initial_accuracy = accuracy_score(y_test, pred_xgb)\n",
        "xgb_initial_accuracy\n",
        "\n",
        "#Hyperparameter Tuning Section to improve performance of the XGBoost model\n",
        "\n",
        "#Setting the parameters to test\n",
        "params = {\n",
        "    \"objective\"         :\"multi:softmax\",\n",
        "    'colsample_bytree'  : [0.3, 0.4, 0.5, 0.7],\n",
        "    'learning_rate'     : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30],\n",
        "    'max_depth'         : [3, 4, 5, 6, 8, 10, 12, 15],\n",
        "    'alpha'             : [2, 4, 8, 10, 15, 20],\n",
        "    'gamma'             : [0.0, 0.1, 0.2, 0.3, 0.4],\n",
        "    'min_child_weight'  : [1, 3, 5, 7],\n",
        "}\n",
        "\n",
        "xgb_classifier = xgb.XGBClassifier()\n",
        "random_search = RandomizedSearchCV(xgb_classifier,param_distributions=params,n_iter=5,scoring='roc_auc',n_jobs=-1,cv=5,verbose=3)\n",
        "\n",
        "random_search.fit(X,y)\n",
        "\n",
        "#Checking to see what the best estimator and parameters are for our model based on the randomized search performed above\n",
        "random_search.best_estimator_\n",
        "random_search.best_params_\n",
        "\n",
        "\n",
        "final_xgb_classifier = xgb.XGBClassifier(alpha=10, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
        "              colsample_bynode=1, colsample_bytree=0.3,\n",
        "              enable_categorical=False, gamma=0.2, gpu_id=0,\n",
        "              importance_type=None, interaction_constraints='',\n",
        "              learning_rate=0.3, max_delta_step=0, max_depth=12,\n",
        "              min_child_weight=7, monotone_constraints='()',\n",
        "              n_estimators=100, n_jobs=12, num_parallel_tree=1,\n",
        "              objective='multi:softprob', predictor='auto', random_state=0,\n",
        "              reg_alpha=10, reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
        "              tree_method='exact', validate_parameters=1, verbosity=1)"
      ],
      "metadata": {
        "id": "EiDd6vR2kUYC",
        "outputId": "918a8734-7c43-47f6-a8a8-85363841d736",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 0.938083\n",
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan]\n",
            "  category=UserWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Utilizing cross validation to evaluate the performance of the model\n",
        "xgb_final_score = cross_val_score(final_xgb_classifier, X, y, cv=10)\n",
        "#Comparing the two arrays from before and after hyperparameter tuning\n",
        "xgb_initial_score\n",
        "xgb_final_score\n",
        "\n",
        "#Fitting our final XGB model on our training data\n",
        "final_xgb_classifier.fit(X_train,y_train)\n",
        "\n",
        "pred_xgb_final = final_xgb_classifier.predict(X_test)\n",
        "\n",
        "mse_xgb_final = np.sqrt(mean_squared_error(y_test, pred_xgb_final))\n",
        "print(\"MSE: %f\" % (mse_xgb_final))\n",
        "\n",
        "xgb_final_accuracy = accuracy_score(y_test, pred_xgb_final)\n",
        "xgb_final_accuracy\n",
        "\n",
        "#After hyperparameter tuning, our MSE decreased from 0.9029 to 0.8575\n"
      ],
      "metadata": {
        "id": "_2PEN_FEkbFh",
        "outputId": "4dc1d432-b8dd-4e5c-b493-2a6f9ec10284",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "10 fits failed out of a total of 10.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "10 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\", line 732, in fit\n",
            "    callbacks=callbacks)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/xgboost/training.py\", line 216, in train\n",
            "    xgb_model=xgb_model, callbacks=callbacks)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/xgboost/training.py\", line 74, in _train_internal\n",
            "    bst.update(dtrain, i, obj)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/xgboost/core.py\", line 1109, in update\n",
            "    dtrain.handle))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/xgboost/core.py\", line 176, in _check_call\n",
            "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
            "xgboost.core.XGBoostError: [12:56:10] /workspace/src/predictor/predictor.cc:21: Unknown predictor type auto\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.7/dist-packages/xgboost/./lib/libxgboost.so(xgboost::Predictor::Create(std::string)+0x3b1) [0x7fcfbb0c7f61]\n",
            "  [bt] (1) /usr/local/lib/python3.7/dist-packages/xgboost/./lib/libxgboost.so(xgboost::gbm::GBTree::Configure(std::vector<std::pair<std::string, std::string>, std::allocator<std::pair<std::string, std::string> > > const&)+0x428) [0x7fcfbb04a7d8]\n",
            "  [bt] (2) /usr/local/lib/python3.7/dist-packages/xgboost/./lib/libxgboost.so(void xgboost::GradientBooster::Configure<std::_Rb_tree_iterator<std::pair<std::string const, std::string> > >(std::_Rb_tree_iterator<std::pair<std::string const, std::string> >, std::_Rb_tree_iterator<std::pair<std::string const, std::string> >)+0xd1) [0x7fcfbb053711]\n",
            "  [bt] (3) /usr/local/lib/python3.7/dist-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x45e) [0x7fcfbb05b08e]\n",
            "  [bt] (4) /usr/local/lib/python3.7/dist-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7fcfbafc2ac2]\n",
            "  [bt] (5) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7fcfebaebdae]\n",
            "  [bt] (6) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x22f) [0x7fcfebaeb71f]\n",
            "  [bt] (7) /usr/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0xd849) [0x7fcfebcfb849]\n",
            "  [bt] (8) /usr/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0xdeaf) [0x7fcfebcfbeaf]\n",
            "\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "XGBoostError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-fc8f442df5f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#Fitting our final XGB model on our training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mfinal_xgb_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mpred_xgb_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_xgb_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    730\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \"\"\"\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mXGBoostError\u001b[0m: [12:56:10] /workspace/src/predictor/predictor.cc:21: Unknown predictor type auto\nStack trace:\n  [bt] (0) /usr/local/lib/python3.7/dist-packages/xgboost/./lib/libxgboost.so(xgboost::Predictor::Create(std::string)+0x3b1) [0x7fcfbb0c7f61]\n  [bt] (1) /usr/local/lib/python3.7/dist-packages/xgboost/./lib/libxgboost.so(xgboost::gbm::GBTree::Configure(std::vector<std::pair<std::string, std::string>, std::allocator<std::pair<std::string, std::string> > > const&)+0x428) [0x7fcfbb04a7d8]\n  [bt] (2) /usr/local/lib/python3.7/dist-packages/xgboost/./lib/libxgboost.so(void xgboost::GradientBooster::Configure<std::_Rb_tree_iterator<std::pair<std::string const, std::string> > >(std::_Rb_tree_iterator<std::pair<std::string const, std::string> >, std::_Rb_tree_iterator<std::pair<std::string const, std::string> >)+0xd1) [0x7fcfbb053711]\n  [bt] (3) /usr/local/lib/python3.7/dist-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x45e) [0x7fcfbb05b08e]\n  [bt] (4) /usr/local/lib/python3.7/dist-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7fcfbafc2ac2]\n  [bt] (5) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7fcfebaebdae]\n  [bt] (6) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x22f) [0x7fcfebaeb71f]\n  [bt] (7) /usr/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0xd849) [0x7fcfebcfb849]\n  [bt] (8) /usr/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0xdeaf) [0x7fcfebcfbeaf]\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SDAyVQe-qJtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "METRICS"
      ],
      "metadata": {
        "id": "578TzW6Cj_Ta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#jp's additions:\n",
        "\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "#F1 score is always between 0 and 1\n",
        "#Score of 0 is bad, score of 1 is good\n",
        "\n",
        "f1_logi = f1_score(y_test, pred_logi, average='macro')\n",
        "f1_xgb = f1_score(y_test, pred_xgb, average='macro')\n",
        "print(\"F1 Logistic (base):\",f1_logi)\n",
        "print(\"F1 Logistic (xgb):\",f1_xgb)\n",
        "\n",
        "\n",
        "f1_rf_macro = f1_score(y_test, clf_y_pred, average='macro')\n",
        "f1_rf_micro = f1_score(y_test, clf_y_pred, average='micro')\n",
        "f1_rf_w = f1_score(y_test, clf_y_pred, average='weighted')\n",
        "\n",
        "print(\"\\nF1 RandomForest (base_macro):\",f1_rf_macro)\n",
        "print(\"F1 RandomForest (base_micro):\",f1_rf_micro)\n",
        "print(\"F1 RandomForest (base_weighted):\",f1_rf_w)\n",
        "\n",
        "\n",
        "print(\"\\n  The difference between macro, micro, and weighted is this:\")\n",
        "print(\"  basically, since we have a 3x3 confusion matrix, we don't only have\")\n",
        "print(\"  ONE kind of false positive, true positive, etc...\")\n",
        "print(\"  the model can predict a true jp as being luke OR fabio, meaning our TN, TP, FN, FP\")\n",
        "print(\"  are not so straightforward\")\n",
        "print(\"\\n  --macro, micro, and weighted are just different ways of combining the 3x3 matrix\")\n",
        "print(\"  to get a better picture of your f1 score\")\n",
        "\n",
        "f1_rf_tuned_macro = f1_score(y_test, clf_pred_final, average='macro')\n",
        "f1_rf_tuned_micro = f1_score(y_test, clf_pred_final, average='micro')\n",
        "f1_rf_tuned_w = f1_score(y_test, clf_pred_final, average='weighted')\n",
        "\n",
        "print(\"\\nF1 RandomForest (tuned_macro):\",f1_rf_tuned_macro)\n",
        "print(\"F1 RandomForest (tuned_micro):\",f1_rf_tuned_micro)\n",
        "print(\"F1 RandomForest (tuned_weighted):\",f1_rf_tuned_w)"
      ],
      "metadata": {
        "id": "h3-9pGE4psvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MCC is Matthews Correlation Coefficient\n",
        "#MCC score is always between -1 and 1\n",
        "#Score of -1 is bad, score of 0 would be an average random prediction, score of 1 is perfect model\n",
        "\n",
        "mcc_logi = matthews_corrcoef(y_test, pred_logi)\n",
        "mcc_xgb = matthews_corrcoef(y_test, pred_xgb)\n",
        "mcc_rf = matthews_corrcoef(y_test, clf_y_pred)\n",
        "mcc_rf_tuned = matthews_corrcoef(y_test, clf_pred_final)\n",
        "\n",
        "print(\"MCC Logistic (base):\",mcc_logi)\n",
        "print(\"MCC Logistic (xgb):\",\"again, python says 'no module named xgboost' when i import xgboost\")\n",
        "print(\"\\nMCC RandomForest (base):\",mcc_rf)\n",
        "print(\"\\nMCC RandomForest (tuned):\",mcc_rf_tuned)\n",
        "\n",
        "\n",
        "\n",
        "#looks like our best model truly is the base random forest\n",
        "pred_xgb"
      ],
      "metadata": {
        "id": "zYk86N-mpvKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Logistic/ Cross Validate Metrics\n",
        "#More metrics\n",
        "accuracy = accuracy_score(y_test, pred_logi)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(classification_report(y_test, pred_logi))\n",
        "\n",
        "print(matthews_corrcoef(y_test, pred_logi))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oNBHt6Ph4VG",
        "outputId": "1e6a22a2-872b-4c70-8a55-1176d1f8547b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.63\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Fabian       0.49      0.44      0.47        97\n",
            "          JP       0.77      0.65      0.71        94\n",
            "        Luke       0.64      0.76      0.70       134\n",
            "\n",
            "    accuracy                           0.63       325\n",
            "   macro avg       0.64      0.62      0.62       325\n",
            "weighted avg       0.64      0.63      0.63       325\n",
            "\n",
            "0.4381607551639556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EABEaNAdh_Z6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}