{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lasmit17/SpotifyProject/blob/master/XGBoost_Collab_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Packages, Libraries, Models...\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import xgboost as xgb \n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, precision_recall_curve, auc, average_precision_score\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "FUrWrHowJVzC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reading CSVs\n",
        "luke_df_2016 = pd.read_csv(f'Luke_2016_Top_Songs.csv')\n",
        "luke_df_2017 = pd.read_csv(f'Luke_2017_Top_Songs.csv')\n",
        "luke_df_2018 = pd.read_csv(f'Luke_2018_Top_Songs.csv')\n",
        "luke_df_2019 = pd.read_csv(f'Luke_2019_Top_Songs.csv')\n",
        "luke_df_2020 = pd.read_csv(f'Luke_2020_Top_Songs.csv')\n",
        "\n",
        "jp_df_2017 = pd.read_csv(f'jp_2017_Top_Songs.csv')\n",
        "jp_df_2018 = pd.read_csv(f\"jp_2018_Top_Songs.csv\")\n",
        "jp_df_2019 = pd.read_csv(f\"jp_2019_Top_Songs.csv\")\n",
        "jp_df_2020 = pd.read_csv(f\"jp_2020_Top_Songs.csv\")\n",
        "\n",
        "fabian_df_2018 = pd.read_csv(f\"FP_2018_Top_Songs.csv\")\n",
        "fabian_df_2019 = pd.read_csv(f\"fp_2019_Top_Songs.csv\")\n",
        "fabian_df_2020 = pd.read_csv(f\"FP_2020_Top_Songs.csv\")\n",
        "fabian_df_2017 = pd.read_csv(f\"FP_2017_Top_Songs.csv\")"
      ],
      "metadata": {
        "id": "nZRvPLZ1Ijdx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Release Year\n",
        "#Creating a function to add a new variable to the dataframes, the song release year\n",
        "def get_years(df):\n",
        "    years = []\n",
        "    for date in df['release_date'].values:\n",
        "        if '-' in date:\n",
        "            years.append(date.split('-')[0])\n",
        "        else:\n",
        "            years.append(date)\n",
        "    df['release_year'] = years\n",
        "    return df\n",
        "\n",
        "\n",
        "#Adding release year to each dataframe for each individual\n",
        "luke_df_2016 = get_years(luke_df_2016)\n",
        "luke_df_2017 = get_years(luke_df_2017)\n",
        "luke_df_2018 = get_years(luke_df_2018)\n",
        "luke_df_2019 = get_years(luke_df_2019)\n",
        "luke_df_2020 = get_years(luke_df_2020)\n",
        "\n",
        "jp_df_2017 = get_years(jp_df_2017)\n",
        "jp_df_2018 = get_years(jp_df_2018)\n",
        "jp_df_2019 = get_years(jp_df_2019)\n",
        "jp_df_2020 = get_years(jp_df_2020)\n",
        "\n",
        "fabian_df_2018 = get_years(fabian_df_2018)\n",
        "fabian_df_2019 = get_years(fabian_df_2019)\n",
        "fabian_df_2020 = get_years(fabian_df_2020)\n",
        "fabian_df_2017 = get_years(fabian_df_2017)"
      ],
      "metadata": {
        "id": "RwqKWmx6ffAo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Joining DataFrames\n",
        "#combining each person's data\n",
        "luke_df_concat = pd.concat([luke_df_2016, luke_df_2017, luke_df_2018, luke_df_2019, luke_df_2020], ignore_index=True, axis=0)\n",
        "luke_df_concat['users_name'] = \"Luke\"\n",
        "\n",
        "jp_df_concat = pd.concat([jp_df_2017, jp_df_2018, jp_df_2019, jp_df_2020], ignore_index=True, axis=0)\n",
        "jp_df_concat['users_name'] = \"JP\"\n",
        "\n",
        "fabian_df_concat = pd.concat([fabian_df_2017, fabian_df_2018, fabian_df_2019, fabian_df_2020], ignore_index=True, axis=0)\n",
        "fabian_df_concat['users_name'] = \"Fabian\"\n",
        "\n",
        "#Combining every data frame together into one\n",
        "all_df = pd.concat([luke_df_concat, jp_df_concat, fabian_df_concat], ignore_index=True, axis=0)\n",
        "\n",
        "all_df[\"release_year\"] = pd.to_numeric(all_df[\"release_year\"])"
      ],
      "metadata": {
        "id": "Y2U4Xn3Hfp2h"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove Repeats\n",
        "# remove repeats on individual playlists\n",
        "def remove_repeats(df):\n",
        "    rows_old = range(len(df['name']))\n",
        "    rows_new = []\n",
        "    skips = []\n",
        "    for i in range(len(df['name'])):\n",
        "        for j in range(i+1, len(df['name'])):\n",
        "            if (df['name'][i] == df['name'][j]) and (df['artist'][i] == df['artist'][j]):\n",
        "                skips.append(j)\n",
        "    for row in rows_old:\n",
        "        if not row in skips:\n",
        "            rows_new.append(row)\n",
        "    df = df.iloc[rows_new,:].reset_index(drop=True)\n",
        "    return df\n",
        "remove_repeats(all_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        },
        "id": "yaFdXkSNfuut",
        "outputId": "fb7721fd-ab3f-4d65-bcd3-327563d870fe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           name                                album  \\\n",
              "0                    In the Bag                             GO:OD AM   \n",
              "1                      Gasoline                    BADLANDS (Deluxe)   \n",
              "2                        Closer                               Closer   \n",
              "3                       Morocco             Mountains Beaches Cities   \n",
              "4                Temporary Love                       Temporary Love   \n",
              "...                         ...                                  ...   \n",
              "1206                       1975                                 1975   \n",
              "1207                 Whasgood?!                           Whasgood?!   \n",
              "1208     You Can't Hold Me Down  An Ordinary Day In An Unusual Place   \n",
              "1209  Satisfied 'N' Tickled Too             Satisfied 'N Tickled Too   \n",
              "1210     This Land Is Your Land                            Naturally   \n",
              "\n",
              "                            artist release_date  length  popularity  \\\n",
              "0                       Mac Miller   2015-09-18  275506          52   \n",
              "1                           Halsey   2015-08-28  199593          73   \n",
              "2                 The Chainsmokers   2016-07-29  244960          85   \n",
              "3                        Moon Taxi   2013-09-10  208080           0   \n",
              "4                       The Brinks   2015-12-04  205129          46   \n",
              "...                            ...          ...     ...         ...   \n",
              "1206                         MAJAN   2019-05-10  223795          54   \n",
              "1207                    blackwave.   2018-06-08  221800          33   \n",
              "1208                           Us3   2001-01-01  261466          44   \n",
              "1209                     Taj Mahal   1976-06-25  326826          43   \n",
              "1210  Sharon Jones & The Dap-Kings   2005-01-25  271440          50   \n",
              "\n",
              "      acousticness  danceability  energy  instrumentalness  ...  loudness  \\\n",
              "0           0.3010         0.717   0.634          0.000000  ...    -6.887   \n",
              "1           0.2230         0.731   0.580          0.000000  ...    -7.328   \n",
              "2           0.4140         0.748   0.524          0.000000  ...    -5.599   \n",
              "3           0.0178         0.616   0.894          0.000103  ...    -3.209   \n",
              "4           0.6560         0.714   0.555          0.000289  ...    -7.550   \n",
              "...            ...           ...     ...               ...  ...       ...   \n",
              "1206        0.2340         0.635   0.473          0.000000  ...   -10.137   \n",
              "1207        0.0311         0.851   0.669          0.000086  ...    -4.259   \n",
              "1208        0.0229         0.824   0.723          0.011100  ...    -4.814   \n",
              "1209        0.7470         0.841   0.591          0.037100  ...    -9.081   \n",
              "1210        0.4010         0.612   0.748          0.000002  ...    -3.654   \n",
              "\n",
              "      speechiness    tempo  valence  time_signature  key  mode  \\\n",
              "0          0.4090  143.812    0.564               4    1     1   \n",
              "1          0.0399  119.997    0.319               4   10     0   \n",
              "2          0.0338   95.010    0.661               4    8     1   \n",
              "3          0.0508  115.077    0.542               4    1     0   \n",
              "4          0.0459  102.971    0.329               4    6     0   \n",
              "...           ...      ...      ...             ...  ...   ...   \n",
              "1206       0.0623  140.094    0.191               4    8     1   \n",
              "1207       0.0721  109.974    0.835               4    1     1   \n",
              "1208       0.0305  116.013    0.963               4    1     1   \n",
              "1209       0.0527  134.796    0.817               4    3     1   \n",
              "1210       0.0318   98.077    0.905               4    6     1   \n",
              "\n",
              "                                       uri release_year  users_name  \n",
              "0     spotify:track:7odIekt1GqLVEAAWdnd9mJ         2015        Luke  \n",
              "1     spotify:track:2IO7yf562c1zLzpanal1DT         2015        Luke  \n",
              "2     spotify:track:7BKLCZ1jbUBVqRi2FVlTVw         2016        Luke  \n",
              "3     spotify:track:30lgD1UuHczwlxa7NZFeSQ         2013        Luke  \n",
              "4     spotify:track:2U6hcDLZHYRSd9Up0mMe9W         2015        Luke  \n",
              "...                                    ...          ...         ...  \n",
              "1206  spotify:track:6mf2YhtRwQUdnORRrRQ3hP         2019      Fabian  \n",
              "1207  spotify:track:5vhwne4NXUgFdtbnTMz37m         2018      Fabian  \n",
              "1208  spotify:track:366E1dYGmFM75DxX0yxlSq         2001      Fabian  \n",
              "1209  spotify:track:4v6gpq8gNsvKekCc2rgXb5         1976      Fabian  \n",
              "1210  spotify:track:3JiUvMTBqbturJ5cKhxgWH         2005      Fabian  \n",
              "\n",
              "[1211 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0865c257-f64e-40b7-b12f-7edf59a5aad9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>album</th>\n",
              "      <th>artist</th>\n",
              "      <th>release_date</th>\n",
              "      <th>length</th>\n",
              "      <th>popularity</th>\n",
              "      <th>acousticness</th>\n",
              "      <th>danceability</th>\n",
              "      <th>energy</th>\n",
              "      <th>instrumentalness</th>\n",
              "      <th>...</th>\n",
              "      <th>loudness</th>\n",
              "      <th>speechiness</th>\n",
              "      <th>tempo</th>\n",
              "      <th>valence</th>\n",
              "      <th>time_signature</th>\n",
              "      <th>key</th>\n",
              "      <th>mode</th>\n",
              "      <th>uri</th>\n",
              "      <th>release_year</th>\n",
              "      <th>users_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In the Bag</td>\n",
              "      <td>GO:OD AM</td>\n",
              "      <td>Mac Miller</td>\n",
              "      <td>2015-09-18</td>\n",
              "      <td>275506</td>\n",
              "      <td>52</td>\n",
              "      <td>0.3010</td>\n",
              "      <td>0.717</td>\n",
              "      <td>0.634</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-6.887</td>\n",
              "      <td>0.4090</td>\n",
              "      <td>143.812</td>\n",
              "      <td>0.564</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>spotify:track:7odIekt1GqLVEAAWdnd9mJ</td>\n",
              "      <td>2015</td>\n",
              "      <td>Luke</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Gasoline</td>\n",
              "      <td>BADLANDS (Deluxe)</td>\n",
              "      <td>Halsey</td>\n",
              "      <td>2015-08-28</td>\n",
              "      <td>199593</td>\n",
              "      <td>73</td>\n",
              "      <td>0.2230</td>\n",
              "      <td>0.731</td>\n",
              "      <td>0.580</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-7.328</td>\n",
              "      <td>0.0399</td>\n",
              "      <td>119.997</td>\n",
              "      <td>0.319</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>spotify:track:2IO7yf562c1zLzpanal1DT</td>\n",
              "      <td>2015</td>\n",
              "      <td>Luke</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Closer</td>\n",
              "      <td>Closer</td>\n",
              "      <td>The Chainsmokers</td>\n",
              "      <td>2016-07-29</td>\n",
              "      <td>244960</td>\n",
              "      <td>85</td>\n",
              "      <td>0.4140</td>\n",
              "      <td>0.748</td>\n",
              "      <td>0.524</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-5.599</td>\n",
              "      <td>0.0338</td>\n",
              "      <td>95.010</td>\n",
              "      <td>0.661</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>spotify:track:7BKLCZ1jbUBVqRi2FVlTVw</td>\n",
              "      <td>2016</td>\n",
              "      <td>Luke</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Morocco</td>\n",
              "      <td>Mountains Beaches Cities</td>\n",
              "      <td>Moon Taxi</td>\n",
              "      <td>2013-09-10</td>\n",
              "      <td>208080</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0178</td>\n",
              "      <td>0.616</td>\n",
              "      <td>0.894</td>\n",
              "      <td>0.000103</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.209</td>\n",
              "      <td>0.0508</td>\n",
              "      <td>115.077</td>\n",
              "      <td>0.542</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>spotify:track:30lgD1UuHczwlxa7NZFeSQ</td>\n",
              "      <td>2013</td>\n",
              "      <td>Luke</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Temporary Love</td>\n",
              "      <td>Temporary Love</td>\n",
              "      <td>The Brinks</td>\n",
              "      <td>2015-12-04</td>\n",
              "      <td>205129</td>\n",
              "      <td>46</td>\n",
              "      <td>0.6560</td>\n",
              "      <td>0.714</td>\n",
              "      <td>0.555</td>\n",
              "      <td>0.000289</td>\n",
              "      <td>...</td>\n",
              "      <td>-7.550</td>\n",
              "      <td>0.0459</td>\n",
              "      <td>102.971</td>\n",
              "      <td>0.329</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>spotify:track:2U6hcDLZHYRSd9Up0mMe9W</td>\n",
              "      <td>2015</td>\n",
              "      <td>Luke</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1206</th>\n",
              "      <td>1975</td>\n",
              "      <td>1975</td>\n",
              "      <td>MAJAN</td>\n",
              "      <td>2019-05-10</td>\n",
              "      <td>223795</td>\n",
              "      <td>54</td>\n",
              "      <td>0.2340</td>\n",
              "      <td>0.635</td>\n",
              "      <td>0.473</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-10.137</td>\n",
              "      <td>0.0623</td>\n",
              "      <td>140.094</td>\n",
              "      <td>0.191</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>spotify:track:6mf2YhtRwQUdnORRrRQ3hP</td>\n",
              "      <td>2019</td>\n",
              "      <td>Fabian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1207</th>\n",
              "      <td>Whasgood?!</td>\n",
              "      <td>Whasgood?!</td>\n",
              "      <td>blackwave.</td>\n",
              "      <td>2018-06-08</td>\n",
              "      <td>221800</td>\n",
              "      <td>33</td>\n",
              "      <td>0.0311</td>\n",
              "      <td>0.851</td>\n",
              "      <td>0.669</td>\n",
              "      <td>0.000086</td>\n",
              "      <td>...</td>\n",
              "      <td>-4.259</td>\n",
              "      <td>0.0721</td>\n",
              "      <td>109.974</td>\n",
              "      <td>0.835</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>spotify:track:5vhwne4NXUgFdtbnTMz37m</td>\n",
              "      <td>2018</td>\n",
              "      <td>Fabian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1208</th>\n",
              "      <td>You Can't Hold Me Down</td>\n",
              "      <td>An Ordinary Day In An Unusual Place</td>\n",
              "      <td>Us3</td>\n",
              "      <td>2001-01-01</td>\n",
              "      <td>261466</td>\n",
              "      <td>44</td>\n",
              "      <td>0.0229</td>\n",
              "      <td>0.824</td>\n",
              "      <td>0.723</td>\n",
              "      <td>0.011100</td>\n",
              "      <td>...</td>\n",
              "      <td>-4.814</td>\n",
              "      <td>0.0305</td>\n",
              "      <td>116.013</td>\n",
              "      <td>0.963</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>spotify:track:366E1dYGmFM75DxX0yxlSq</td>\n",
              "      <td>2001</td>\n",
              "      <td>Fabian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1209</th>\n",
              "      <td>Satisfied 'N' Tickled Too</td>\n",
              "      <td>Satisfied 'N Tickled Too</td>\n",
              "      <td>Taj Mahal</td>\n",
              "      <td>1976-06-25</td>\n",
              "      <td>326826</td>\n",
              "      <td>43</td>\n",
              "      <td>0.7470</td>\n",
              "      <td>0.841</td>\n",
              "      <td>0.591</td>\n",
              "      <td>0.037100</td>\n",
              "      <td>...</td>\n",
              "      <td>-9.081</td>\n",
              "      <td>0.0527</td>\n",
              "      <td>134.796</td>\n",
              "      <td>0.817</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>spotify:track:4v6gpq8gNsvKekCc2rgXb5</td>\n",
              "      <td>1976</td>\n",
              "      <td>Fabian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1210</th>\n",
              "      <td>This Land Is Your Land</td>\n",
              "      <td>Naturally</td>\n",
              "      <td>Sharon Jones &amp; The Dap-Kings</td>\n",
              "      <td>2005-01-25</td>\n",
              "      <td>271440</td>\n",
              "      <td>50</td>\n",
              "      <td>0.4010</td>\n",
              "      <td>0.612</td>\n",
              "      <td>0.748</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.654</td>\n",
              "      <td>0.0318</td>\n",
              "      <td>98.077</td>\n",
              "      <td>0.905</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>spotify:track:3JiUvMTBqbturJ5cKhxgWH</td>\n",
              "      <td>2005</td>\n",
              "      <td>Fabian</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1211 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0865c257-f64e-40b7-b12f-7edf59a5aad9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0865c257-f64e-40b7-b12f-7edf59a5aad9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0865c257-f64e-40b7-b12f-7edf59a5aad9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Scaling Variables 0<var<1\n",
        "# Create function to do linear transformation on variable to change value to [0,1]\n",
        "def convert_scale(df, col):\n",
        "    df[col + '_old'] = df[col]\n",
        "    new_max = 1\n",
        "    new_min = 0\n",
        "    new_range = new_max-new_min\n",
        "    max_val = df[col].max()\n",
        "    min_val=df[col].min()\n",
        "    val_range = max_val - min_val\n",
        "    df[col]=df[col].apply(lambda x: (((x-min_val)*new_range)/val_range)+new_min)\n",
        "    return\n",
        "\n",
        "\n",
        "\n",
        "#Setting the numerical spotify features\n",
        "numeric_spotify_features = ['energy',\n",
        "    'valence',\n",
        "    'danceability',\n",
        "    'liveness',\n",
        "    'speechiness',\n",
        "    'instrumentalness',\n",
        "    'acousticness',\n",
        "    'loudness',\n",
        "    'length',\n",
        "    'popularity',\n",
        "    'tempo',\n",
        "    'release_year']\n",
        "\n",
        "\n",
        "for col in numeric_spotify_features:\n",
        "    convert_scale(all_df, col)"
      ],
      "metadata": {
        "id": "QR-1xwRUf06I"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#HotEncoding Variables\n",
        "#Now we need to address the categorical variables. First, we will utilize One Hot Encoder\n",
        "ohe = OneHotEncoder()\n",
        "ohe_results = ohe.fit_transform(all_df[['time_signature', 'mode', 'key']])\n",
        "onehot_df = pd.DataFrame(ohe_results.toarray(), columns=['time_signature_1', 'time_signature_2',\n",
        "                                                     'time_signature_3', 'time_signature_4',\n",
        "                                                     'mode_1', 'mode_2',\n",
        "                                                     'key_1', 'key_2', 'key_3', 'key_4', 'key_5', 'key_6',\n",
        "                                                     'key_7', 'key_8', 'key_9', 'key_10', 'key_11', 'key_12'])\n",
        "all_df = pd.concat([all_df, onehot_df], axis=1)"
      ],
      "metadata": {
        "id": "JXFqb8Ocf9QA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Combine all Features\n",
        "#Finally, we combine all of our features used for prediction into one list\n",
        "all_spotify_features = ['energy',\n",
        "    'valence',\n",
        "    'danceability',\n",
        "    'liveness',\n",
        "    'speechiness',\n",
        "    'instrumentalness',\n",
        "    'acousticness',\n",
        "    'loudness',\n",
        "    'length',\n",
        "    'popularity',\n",
        "    'tempo',\n",
        "    'release_year',\n",
        "    'time_signature_1',\n",
        "    'time_signature_2',\n",
        "    'time_signature_3',\n",
        "    'time_signature_4',\n",
        "    'mode_1',\n",
        "    'mode_2',\n",
        "    'key_1',\n",
        "    'key_2',\n",
        "    'key_3',\n",
        "    'key_4',\n",
        "    'key_5',\n",
        "    'key_6',\n",
        "    'key_7',\n",
        "    'key_8',\n",
        "    'key_9',\n",
        "    'key_10',\n",
        "    'key_11',\n",
        "    'key_12']\n"
      ],
      "metadata": {
        "id": "UIpW_65VgNHa"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PREP FINISHED\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "MODELS BEGIN"
      ],
      "metadata": {
        "id": "4Y2MEFyGgTsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Set X,Y, Split Train/Test\n",
        "#Now, we can finally set our X and y values. X will be all the Spotify features provided above and y will be each individual's name\n",
        "X = all_df[all_spotify_features]\n",
        "y = all_df['users_name']\n",
        "\n",
        "#Here we split our data up into training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=123)\n",
        "\n"
      ],
      "metadata": {
        "id": "55jwbt91gXG2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOGISTIC REGRESSION"
      ],
      "metadata": {
        "id": "jq0Hh6lsgkOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Pipeline, Fitting, Predicting\n",
        "#Setting up a pipeline that scales and then utilizes multinomial logistic regression\n",
        "pipe = Pipeline([('scaler', StandardScaler()),     # Step 1\n",
        "                 ('model', LogisticRegression(multi_class='multinomial', solver='lbfgs')) # Step 2\n",
        "                 ])\n",
        "#Fitting and predicting with our data\n",
        "pipe.fit(X_train, y_train)\n",
        "pred_logi = pipe.predict(X_test)\n",
        "\n",
        "#print(\"Accuracy:\",metrics.accuracy_score(y_test, pred_logi))"
      ],
      "metadata": {
        "id": "sPViZZ1LgiB-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cross-validation\n",
        "cv = KFold(n_splits=10, random_state=123, shuffle=True)\n",
        "scores = cross_val_score(pipe, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "scores\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vpy8M2vagtTW",
        "outputId": "581c0d5c-3e84-42a0-c67d-46781ca7019c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.67346939, 0.62244898, 0.59183673, 0.67346939, 0.59183673,\n",
              "       0.6185567 , 0.59793814, 0.58762887, 0.58762887, 0.53608247])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBOOST"
      ],
      "metadata": {
        "id": "MUem54zdkJnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#XGBoost\n",
        "\n",
        "#Setting Luke to 2, JP to 1, and Fabian to 0 in order to utilize XGBoost\n",
        "#This is our base model for XGBoost\n",
        "all_df[\"users_name\"] = all_df['users_name'].replace({\"Luke\":2,\"JP\":1,\"Fabian\":0})\n",
        "\n",
        "X = all_df[all_spotify_features]\n",
        "y = all_df['users_name']\n",
        "data_dmatrix = xgb.DMatrix(data=X,label=y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=123)\n",
        "\n",
        "xg_reg = xgb.XGBClassifier(objective ='multi:softmax', colsample_bytree = 0.3, learning_rate = 0.1,\n",
        "                max_depth = 5, alpha = 10, n_estimators = 10, num_classes = 3)\n",
        "xg_reg.fit(X_train,y_train)\n",
        "all_df.users_name\n",
        "pred_xgb = xg_reg.predict(X_test)"
      ],
      "metadata": {
        "id": "ACNky-w8htn7"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#XGBoost parameters\n",
        "mse_xgb = np.sqrt(mean_squared_error(y_test, pred_xgb))\n",
        "print(\"MSE: %f\" % (mse_xgb))\n",
        "\n",
        "xgb_initial_score = cross_val_score(xg_reg, X, y, cv=10)\n",
        "xgb_initial_score\n",
        "\n",
        "xgb_initial_accuracy = accuracy_score(y_test, pred_xgb)\n",
        "xgb_initial_accuracy\n",
        "\n",
        "#Hyperparameter Tuning Section to improve performance of the XGBoost model\n",
        "\n",
        "#Setting the parameters to test\n",
        "params = {\n",
        "    \"objective\"         :\"multi:softmax\",\n",
        "    'colsample_bytree'  : [0.3, 0.4, 0.5, 0.7],\n",
        "    'learning_rate'     : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30],\n",
        "    'max_depth'         : [3, 4, 5, 6, 8, 10, 12, 15],\n",
        "    'alpha'             : [2, 4, 8, 10, 15, 20],\n",
        "    'gamma'             : [0.0, 0.1, 0.2, 0.3, 0.4],\n",
        "    'min_child_weight'  : [1, 3, 5, 7],\n",
        "}\n",
        "\n",
        "xgb_classifier = xgb.XGBClassifier()\n",
        "random_search = RandomizedSearchCV(xgb_classifier,param_distributions=params,n_iter=5,scoring='roc_auc',n_jobs=-1,cv=5,verbose=3)\n",
        "\n",
        "random_search.fit(X,y)\n",
        "\n",
        "#Checking to see what the best estimator and parameters are for our model based on the randomized search performed above\n",
        "random_search.best_estimator_\n",
        "random_search.best_params_\n",
        "\n",
        "\n",
        "final_xgb_classifier = xgb.XGBClassifier(alpha=10, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
        "              colsample_bynode=1, colsample_bytree=0.3,\n",
        "              enable_categorical=False, gamma=0.2, gpu_id=0,\n",
        "              importance_type=None, interaction_constraints='',\n",
        "              learning_rate=0.3, max_delta_step=0, max_depth=12,\n",
        "              min_child_weight=7, monotone_constraints='()',\n",
        "              n_estimators=100, n_jobs=12, num_parallel_tree=1,\n",
        "              objective='multi:softprob', predictor='auto', random_state=0,\n",
        "              reg_alpha=10, reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
        "              tree_method='exact', validate_parameters=1, verbosity=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiDd6vR2kUYC",
        "outputId": "918a8734-7c43-47f6-a8a8-85363841d736"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 0.938083\n",
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan]\n",
            "  category=UserWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Utilizing cross validation to evaluate the performance of the model\n",
        "xgb_final_score = cross_val_score(final_xgb_classifier, X, y, cv=10)\n",
        "#Comparing the two arrays from before and after hyperparameter tuning\n",
        "xgb_initial_score\n",
        "xgb_final_score\n",
        "\n",
        "#Fitting our final XGB model on our training data\n",
        "final_xgb_classifier.fit(X_train,y_train)\n",
        "\n",
        "pred_xgb_final = final_xgb_classifier.predict(X_test)\n",
        "\n",
        "mse_xgb_final = np.sqrt(mean_squared_error(y_test, pred_xgb_final))\n",
        "print(\"MSE: %f\" % (mse_xgb_final))\n",
        "\n",
        "xgb_final_accuracy = accuracy_score(y_test, pred_xgb_final)\n",
        "xgb_final_accuracy\n",
        "\n",
        "#After hyperparameter tuning, our MSE decreased from 0.9029 to 0.8575\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_2PEN_FEkbFh",
        "outputId": "4dc1d432-b8dd-4e5c-b493-2a6f9ec10284"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "10 fits failed out of a total of 10.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "10 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\", line 732, in fit\n",
            "    callbacks=callbacks)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/xgboost/training.py\", line 216, in train\n",
            "    xgb_model=xgb_model, callbacks=callbacks)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/xgboost/training.py\", line 74, in _train_internal\n",
            "    bst.update(dtrain, i, obj)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/xgboost/core.py\", line 1109, in update\n",
            "    dtrain.handle))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/xgboost/core.py\", line 176, in _check_call\n",
            "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
            "xgboost.core.XGBoostError: [12:56:10] /workspace/src/predictor/predictor.cc:21: Unknown predictor type auto\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.7/dist-packages/xgboost/./lib/libxgboost.so(xgboost::Predictor::Create(std::string)+0x3b1) [0x7fcfbb0c7f61]\n",
            "  [bt] (1) /usr/local/lib/python3.7/dist-packages/xgboost/./lib/libxgboost.so(xgboost::gbm::GBTree::Configure(std::vector<std::pair<std::string, std::string>, std::allocator<std::pair<std::string, std::string> > > const&)+0x428) [0x7fcfbb04a7d8]\n",
            "  [bt] (2) /usr/local/lib/python3.7/dist-packages/xgboost/./lib/libxgboost.so(void xgboost::GradientBooster::Configure<std::_Rb_tree_iterator<std::pair<std::string const, std::string> > >(std::_Rb_tree_iterator<std::pair<std::string const, std::string> >, std::_Rb_tree_iterator<std::pair<std::string const, std::string> >)+0xd1) [0x7fcfbb053711]\n",
            "  [bt] (3) /usr/local/lib/python3.7/dist-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x45e) [0x7fcfbb05b08e]\n",
            "  [bt] (4) /usr/local/lib/python3.7/dist-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7fcfbafc2ac2]\n",
            "  [bt] (5) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7fcfebaebdae]\n",
            "  [bt] (6) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x22f) [0x7fcfebaeb71f]\n",
            "  [bt] (7) /usr/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0xd849) [0x7fcfebcfb849]\n",
            "  [bt] (8) /usr/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0xdeaf) [0x7fcfebcfbeaf]\n",
            "\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "XGBoostError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-fc8f442df5f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#Fitting our final XGB model on our training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mfinal_xgb_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mpred_xgb_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_xgb_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    730\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \"\"\"\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mXGBoostError\u001b[0m: [12:56:10] /workspace/src/predictor/predictor.cc:21: Unknown predictor type auto\nStack trace:\n  [bt] (0) /usr/local/lib/python3.7/dist-packages/xgboost/./lib/libxgboost.so(xgboost::Predictor::Create(std::string)+0x3b1) [0x7fcfbb0c7f61]\n  [bt] (1) /usr/local/lib/python3.7/dist-packages/xgboost/./lib/libxgboost.so(xgboost::gbm::GBTree::Configure(std::vector<std::pair<std::string, std::string>, std::allocator<std::pair<std::string, std::string> > > const&)+0x428) [0x7fcfbb04a7d8]\n  [bt] (2) /usr/local/lib/python3.7/dist-packages/xgboost/./lib/libxgboost.so(void xgboost::GradientBooster::Configure<std::_Rb_tree_iterator<std::pair<std::string const, std::string> > >(std::_Rb_tree_iterator<std::pair<std::string const, std::string> >, std::_Rb_tree_iterator<std::pair<std::string const, std::string> >)+0xd1) [0x7fcfbb053711]\n  [bt] (3) /usr/local/lib/python3.7/dist-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x45e) [0x7fcfbb05b08e]\n  [bt] (4) /usr/local/lib/python3.7/dist-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7fcfbafc2ac2]\n  [bt] (5) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7fcfebaebdae]\n  [bt] (6) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x22f) [0x7fcfebaeb71f]\n  [bt] (7) /usr/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0xd849) [0x7fcfebcfb849]\n  [bt] (8) /usr/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0xdeaf) [0x7fcfebcfbeaf]\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RANDOM FOREST"
      ],
      "metadata": {
        "id": "EH6Pin7Yqdha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Now we'll work to build a Random Forest model. This will serve as our base Random Forest model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "#Bringing in the Random Forest Classifier\n",
        "clf = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "#Train the model using the training sets created earlier on\n",
        "clf.fit(X_train,y_train)\n",
        "\n",
        "clf_y_pred = clf.predict(X_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "SDAyVQe-qJtQ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking to see which parameters are being utilized by Random Forest\n",
        "clf.get_params()\n",
        "\n",
        "n_estimators = [5,20,50,100]\n",
        "max_features = ['auto', 'sqrt']\n",
        "max_depth = [int(x) for x in np.linspace(10, 120, num = 12)]\n",
        "min_samples_split = [2, 6, 10]\n",
        "min_samples_leaf = [1, 3, 4]\n",
        "bootstrap = [True, False]\n",
        "\n",
        "clf_params = {\n",
        "    'n_estimators'      : n_estimators,\n",
        "    'max_features'      : max_features,\n",
        "    'max_depth'         : max_depth,\n",
        "    'min_samples_split' : min_samples_split,\n",
        "    'min_samples_leaf'  : min_samples_leaf,\n",
        "    'bootstrap'          : bootstrap\n",
        "}\n",
        "\n",
        "clf_random = RandomizedSearchCV(estimator = clf,param_distributions = clf_params,\n",
        "               n_iter = 100, cv = 5, verbose=2, random_state=35, n_jobs = -1)\n",
        "\n",
        "clf_random.fit(X_train, y_train)\n",
        "\n",
        "#Now lets see what the best parameters are in this case\n",
        "clf_random.best_params_\n",
        "\n",
        "{'n_estimators': 50,\n",
        " 'min_samples_split': 10,\n",
        " 'min_samples_leaf': 3,\n",
        " 'max_features': 'auto',\n",
        " 'max_depth': 90,\n",
        " 'bootstrap': False}\n",
        "\n",
        "#Creating a RF model with the best parameters\n",
        "clf_final = RandomForestClassifier(n_estimators = 50,\n",
        " min_samples_split = 10,\n",
        " min_samples_leaf = 3,\n",
        " max_features = 'auto',\n",
        " max_depth = 90,\n",
        " bootstrap = False)\n",
        "\n",
        "#Fitting the new model to the training data\n",
        "clf_final.fit(X_train,y_train)\n",
        "clf_pred_final = clf_final.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, clf_pred_final))\n",
        "\n",
        "clf_final_score = cross_val_score(clf_final, X, y, cv=10)\n",
        "clf_initial_score\n",
        "clf_final_score\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LW75t9Rwqm9G",
        "outputId": "fcb5128b-9c90-4976-cdaf-704452ec0570"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
            "Accuracy: 0.6738461538461539\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.63846154, 0.6       , 0.71538462, 0.70769231, 0.66923077,\n",
              "       0.63076923, 0.71538462, 0.76153846, 0.64615385, 0.66153846])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "METRICS"
      ],
      "metadata": {
        "id": "578TzW6Cj_Ta"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o629_dzDqmad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#jp's additions:\n",
        "\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "#F1 score is always between 0 and 1\n",
        "#Score of 0 is bad, score of 1 is good\n",
        "\n",
        "f1_logi = f1_score(y_test, pred_logi, average='macro')\n",
        "f1_xgb = f1_score(y_test, pred_xgb, average='macro')\n",
        "print(\"F1 Logistic (base):\",f1_logi)\n",
        "print(\"F1 Logistic (xgb):\",f1_xgb)\n",
        "\n",
        "\n",
        "f1_rf_macro = f1_score(y_test, clf_y_pred, average='macro')\n",
        "f1_rf_micro = f1_score(y_test, clf_y_pred, average='micro')\n",
        "f1_rf_w = f1_score(y_test, clf_y_pred, average='weighted')\n",
        "\n",
        "print(\"\\nF1 RandomForest (base_macro):\",f1_rf_macro)\n",
        "print(\"F1 RandomForest (base_micro):\",f1_rf_micro)\n",
        "print(\"F1 RandomForest (base_weighted):\",f1_rf_w)\n",
        "\n",
        "\n",
        "print(\"\\n  The difference between macro, micro, and weighted is this:\")\n",
        "print(\"  basically, since we have a 3x3 confusion matrix, we don't only have\")\n",
        "print(\"  ONE kind of false positive, true positive, etc...\")\n",
        "print(\"  the model can predict a true jp as being luke OR fabio, meaning our TN, TP, FN, FP\")\n",
        "print(\"  are not so straightforward\")\n",
        "print(\"\\n  --macro, micro, and weighted are just different ways of combining the 3x3 matrix\")\n",
        "print(\"  to get a better picture of your f1 score\")\n",
        "\n",
        "f1_rf_tuned_macro = f1_score(y_test, clf_pred_final, average='macro')\n",
        "f1_rf_tuned_micro = f1_score(y_test, clf_pred_final, average='micro')\n",
        "f1_rf_tuned_w = f1_score(y_test, clf_pred_final, average='weighted')\n",
        "\n",
        "print(\"\\nF1 RandomForest (tuned_macro):\",f1_rf_tuned_macro)\n",
        "print(\"F1 RandomForest (tuned_micro):\",f1_rf_tuned_micro)\n",
        "print(\"F1 RandomForest (tuned_weighted):\",f1_rf_tuned_w)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "h3-9pGE4psvt",
        "outputId": "ef20e3ea-b0d3-47f7-df01-583ebe8a1a73"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-779c060bd956>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#Score of 0 is bad, score of 1 is good\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mf1_logi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_logi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mf1_xgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_xgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"F1 Logistic (base):\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf1_logi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m         \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m     )\n\u001b[1;32m   1133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1268\u001b[0m         \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"f-score\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m         \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1270\u001b[0;31m         \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1271\u001b[0m     )\n\u001b[1;32m   1272\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1544\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1546\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1351\u001b[0;31m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1352\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1353\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;31m# Check that we don't mix string type with number type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mix of label input types (string and number)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Mix of label input types (string and number)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#MCC is Matthews Correlation Coefficient\n",
        "#MCC score is always between -1 and 1\n",
        "#Score of -1 is bad, score of 0 would be an average random prediction, score of 1 is perfect model\n",
        "\n",
        "mcc_logi = matthews_corrcoef(y_test, pred_logi)\n",
        "mcc_xgb = matthews_corrcoef(y_test, pred_xgb)\n",
        "mcc_rf = matthews_corrcoef(y_test, clf_y_pred)\n",
        "mcc_rf_tuned = matthews_corrcoef(y_test, clf_pred_final)\n",
        "\n",
        "print(\"MCC Logistic (base):\",mcc_logi)\n",
        "print(\"MCC Logistic (xgb):\",\"again, python says 'no module named xgboost' when i import xgboost\")\n",
        "print(\"\\nMCC RandomForest (base):\",mcc_rf)\n",
        "print(\"\\nMCC RandomForest (tuned):\",mcc_rf_tuned)\n",
        "\n",
        "\n",
        "\n",
        "#looks like our best model truly is the base random forest\n",
        "pred_xgb"
      ],
      "metadata": {
        "id": "zYk86N-mpvKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Logistic/ Cross Validate Metrics\n",
        "#More metrics\n",
        "accuracy = accuracy_score(y_test, pred_logi)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(classification_report(y_test, pred_logi))\n",
        "\n",
        "print(matthews_corrcoef(y_test, pred_logi))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Evaluating the base Random Forest Model\n",
        "\n",
        "\n",
        "clf_initial_score = cross_val_score(clf, X, y, cv=10)\n",
        "clf_initial_score\n",
        "\n",
        "#Our base RF model has an accuracy of about 69.5%"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "5oNBHt6Ph4VG",
        "outputId": "e3da47e8-70e0-4176-d13c-3c7127c6e0f4"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.00\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-91dc4b82cdb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_logi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Accuracy: {accuracy:.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_logi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatthews_corrcoef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_logi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2112\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2113\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2114\u001b[0m         \u001b[0mlabels_given\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2115\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;31m# Check that we don't mix string type with number type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mix of label input types (string and number)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Mix of label input types (string and number)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Confusion for Random Forest (base model)\n",
        "confusion_matrix_RF = metrics.confusion_matrix(y_test, clf_y_pred)\n",
        "\n",
        "cm_display_RF = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix_RF, \n",
        "                                                display_labels = [\"Fabian\", \"JP\", \"Luke\"])\n",
        "\n",
        "cm_display_RFT.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "EABEaNAdh_Z6",
        "outputId": "f99faf8e-c1c2-4073-edfe-2a66369fb78d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RbpWhhpi3RqT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
